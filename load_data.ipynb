{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import Normalize, ToTensor, Compose, Resize\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_transform = Compose([\n",
    "    Resize((256, 256)),\n",
    "    ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir_images, root_dir_labels, transform=None):\n",
    "        self.root_dir_images = root_dir_images\n",
    "        self.root_dir_labels = root_dir_labels\n",
    "        self.image_files = os.listdir(root_dir_images)\n",
    "        self.label_files = os.listdir(root_dir_labels)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir_images, self.image_files[idx])\n",
    "        label_name = os.path.join(self.root_dir_labels, self.label_files[idx])\n",
    "        image = Image.open(img_name)\n",
    "        with open(label_name, 'r') as file:\n",
    "            label_str = file.readline().strip()  # Read the label string\n",
    "            # Parse the label string to obtain four floats\n",
    "            label = [float(x) for x in label_str.split()]\n",
    "            label = torch.tensor(label, dtype=torch.float32)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to your data\n",
    "data_dir = 'data'\n",
    "train_dir_images = os.path.join(data_dir, 'train', 'images')\n",
    "train_dir_labels = os.path.join(data_dir, 'train', 'labels')\n",
    "valid_dir_images = os.path.join(data_dir, 'valid', 'images')\n",
    "valid_dir_labels = os.path.join(data_dir, 'valid', 'labels')\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CustomDataset(root_dir_images=train_dir_images, root_dir_labels=train_dir_labels, transform=base_transform)\n",
    "valid_dataset = CustomDataset(root_dir_images=valid_dir_images, root_dir_labels=valid_dir_labels, transform=base_transform)\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0., 0., 0.])\n",
      "Standard deviation: tensor([0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "mean = torch.zeros(3)\n",
    "std = torch.zeros(3)\n",
    "\n",
    "SUBSET_SIZE = 1000\n",
    "\n",
    "# Create a subset of the dataset\n",
    "subset_indices = torch.randperm(len(train_dataset))[:SUBSET_SIZE]\n",
    "subset = torch.utils.data.Subset(train_dataset, subset_indices)\n",
    "\n",
    "for image, label in subset:\n",
    "    mean += image.mean(dim = (1,2))\n",
    "    std += image.std(dim = (1,2))\n",
    "\n",
    "mean /= len(subset)\n",
    "std /= len(subset)\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Standard deviation:\", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-e27ed269d0bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Application Support/mu/mu_venv-38-20210322-085656/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT_co\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-36dd0ee455ba>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mlabel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "subset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for image, label in subset:\n",
    "    if i == 0:\n",
    "        print(image.mean(dim = (1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0996, 0.0786, 0.0875])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = train_dataset[4]\n",
    "image.mean(dim = (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final transformation\n",
    "final_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(means, sds)  # Apply normalization using the computed mean and std\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate datasets\n",
    "train_dataset = CustomDataset(root_dir_images=train_dir_images, root_dir_labels=train_dir_labels, transform=final_transform)\n",
    "valid_dataset = CustomDataset(root_dir_images=valid_dir_images, root_dir_labels=valid_dir_labels, transform=final_transform)\n",
    "\n",
    "# Recreate DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[399.3104, 399.3104, 399.3104,  ..., 399.3104, 399.3104, 399.3104],\n",
       "         [399.3104, 399.3104, 399.3104,  ..., 399.3104, 399.3104, 399.3104],\n",
       "         [399.3104, 399.3104, 399.3104,  ..., 399.3104, 399.3104, 399.3104],\n",
       "         ...,\n",
       "         [399.3104, 399.3104, 399.3104,  ..., 399.3104, 399.3104, 399.3104],\n",
       "         [399.3104, 399.3104, 399.3104,  ..., 399.3104, 399.3104, 399.3104],\n",
       "         [399.3104, 399.3104, 399.3104,  ..., 399.3104, 399.3104, 399.3104]],\n",
       "\n",
       "        [[376.1889, 376.1889, 376.1889,  ..., 376.1889, 376.1889, 376.1889],\n",
       "         [376.1889, 376.1889, 376.1889,  ..., 376.1889, 376.1889, 376.1889],\n",
       "         [376.1889, 376.1889, 376.1889,  ..., 376.1889, 376.1889, 376.1889],\n",
       "         ...,\n",
       "         [376.1889, 376.1889, 376.1889,  ..., 376.1889, 376.1889, 376.1889],\n",
       "         [376.1889, 376.1889, 376.1889,  ..., 376.1889, 376.1889, 376.1889],\n",
       "         [376.1889, 376.1889, 376.1889,  ..., 376.1889, 376.1889, 376.1889]],\n",
       "\n",
       "        [[481.2291, 481.2291, 481.2291,  ..., 481.2291, 481.2291, 481.2291],\n",
       "         [481.2291, 481.2291, 481.2291,  ..., 481.2291, 481.2291, 481.2291],\n",
       "         [481.2291, 481.2291, 481.2291,  ..., 481.2291, 481.2291, 481.2291],\n",
       "         ...,\n",
       "         [481.2291, 481.2291, 481.2291,  ..., 481.2291, 481.2291, 481.2291],\n",
       "         [481.2291, 481.2291, 481.2291,  ..., 481.2291, 481.2291, 481.2291],\n",
       "         [481.2291, 481.2291, 481.2291,  ..., 481.2291, 481.2291, 481.2291]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1161.1423, 1042.7136, 1430.7164])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[0].mean()\n",
    "image.mean(dim = (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10188"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16958e3d0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_np = image.permute(1, 2, 0).numpy()\n",
    "plt.imshow(image_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "\"Python/Mu (mu_venv-38-20210322-085656)\"",
   "language": "python",
   "name": "mu_venv-38-20210322-085656"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
